{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "capstone_Elmo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLUMNjrWHVRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e7164a-850e-4bb0-d0be-ed0c5569942f"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2HqB11UuEAa",
        "outputId": "d4e9ef18-3e27-4f2a-9da7-108ab7e6952b"
      },
      "source": [
        "! pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 52.8MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: JPype1, colorama, tweepy, beautifulsoup4, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve78bK4-zBqK"
      },
      "source": [
        "# !pip install gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEPwd9cy-8Sa"
      },
      "source": [
        "# !pip install fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04l9HIQup3fu"
      },
      "source": [
        "# ! pip install senticnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PmvpUbIp7Vr"
      },
      "source": [
        "# from senticnet.babelsenticnet import BabelSenticNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rcenv-NYp_cd"
      },
      "source": [
        "# sn = BabelSenticNet('kr')\n",
        "# sn.concept('사랑')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKMJEPl-uCYp"
      },
      "source": [
        "# from sklearn.utils import class_weight\n",
        "# class_weights_fci = class_weight.compute_class_weight('balanced', np.unique(data_ver2['Emotion']), data_ver2['Emotion'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psKISsXWuxYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16a7ee4-1b1e-47bc-9fb4-1380ef9c2026"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout, GRU, Conv1D,Flatten,GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Bidirectional"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1L_SgkHti3r"
      },
      "source": [
        "# def featurize_rnn(corpus,wdim,maxlen):\n",
        "#     rnn_total = np.zeros((len(corpus),maxlen,wdim))\n",
        "#     for i in range(len(corpus)):\n",
        "#         if i%1000 ==0:\n",
        "#             print(i)\n",
        "#         s = corpus[i]\n",
        "#         for j in range(len(s)):\n",
        "#             if s[-j-1] in data_ver2['Sentence'] and j < maxlen:\n",
        "#                 rnn_total[i][-j-1,:] = model_ft[s[-j-1]]\n",
        "#     return rnn_total\n",
        "\n",
        "# data = featurize_rnn(tokenized_data,100,30)\n",
        "\n",
        "# from keras.layers import LSTM\n",
        "# from keras.layers import Bidirectional\n",
        "\n",
        "# def validate_bilstm(result,y,hidden_lstm,hidden_dim,cw,filename):\n",
        "#     model = Sequential()\n",
        "#     model.add(Bidirectional(LSTM(hidden_lstm), input_shape=(len(result[0]), len(result[0][0]))))\n",
        "#     model.add(layers.Dense(hidden_dim, activation='relu'))\n",
        "#     model.add(layers.Dense(int(max(y)+1), activation='softmax'))\n",
        "#     model.summary()\n",
        "#     model.compile(optimizer='Adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "#     filepath=filename+\"-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "#     checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, mode='max')\n",
        "#     callbacks_list = [metricsf1macro,checkpoint]\n",
        "#     model.fit(result,y,validation_split=0.1,epochs=30,batch_size=16,callbacks=callbacks_list,class_weight=cw)\n",
        "\n",
        "# validate_bilstm(data,data_ver2['Emotion'],32,128,class_weights_fci,'model/tutorial/rec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9uDwINArYU1"
      },
      "source": [
        "# for t in tokenized_data[0]:\n",
        "#   print(t)\n",
        "#   try:\n",
        "#     print(sn.concept(t))\n",
        "#   except:\n",
        "#     continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qnO5hjX_e0z"
      },
      "source": [
        "#! git clone https://github.com/facebookresearch/fastText.git\n",
        "# ! cd fastText\n",
        "# ! sudo python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO1yUs52tqOg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRsWEM2UuCA5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b60a4e9d-0b0a-41a7-a9ff-1f278910d547"
      },
      "source": [
        "data_ver1 = pd.read_csv('train.csv')\n",
        "data_ver2= pd.read_csv('train2.csv')\n",
        "data_ver2.drop(list(range(204,505)), inplace= True)\n",
        "data_ver2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>그 사람이 죽어버렸으면 좋겠어요</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>오늘 진짜 짜증나</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>맛집이라 해서 갔는데 맛이 쓰레기야</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>과제가 너무 많아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>오늘도 야근이야</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>나아지고 있는 거 같아</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>주말이야</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>너무 고마워</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>585</th>\n",
              "      <td>결혼할 거 같아</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>행복한 하루야</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>286 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Sentence  Emotion\n",
              "0      그 사람이 죽어버렸으면 좋겠어요        0\n",
              "1              오늘 진짜 짜증나        0\n",
              "2    맛집이라 해서 갔는데 맛이 쓰레기야        0\n",
              "3              과제가 너무 많아        0\n",
              "4               오늘도 야근이야        0\n",
              "..                   ...      ...\n",
              "582         나아지고 있는 거 같아        3\n",
              "583                 주말이야        3\n",
              "584               너무 고마워        3\n",
              "585             결혼할 거 같아        3\n",
              "586              행복한 하루야        3\n",
              "\n",
              "[286 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "CqeVR1OtB5Gc",
        "outputId": "afc84317-43c1-466b-f108-e8e7e8d430b6"
      },
      "source": [
        "(data_ver2[data_ver2['Emotion']==1])#389 -> 90\r\n",
        "#len(data_ver2[data_ver2['Emotion']==0])#77\r\n",
        "#len(data_ver2[data_ver2['Emotion']==2])#31\r\n",
        "#len(data_ver2[data_ver2['Emotion']==3])#90\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>술 먹고 싶어요</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>죽고 싶어</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>울고 싶어</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>노력해서 되는 일이 있을까?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>너무 지친다</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>끝나니까 허무하다</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>꿈이 이뤄질까</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>내가 너무 소심한가</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>말실수 한거 같아</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>난 머리가 너무 나빠</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Sentence  Emotion\n",
              "10          술 먹고 싶어요        1\n",
              "11             죽고 싶어        1\n",
              "12             울고 싶어        1\n",
              "13   노력해서 되는 일이 있을까?        1\n",
              "14            너무 지친다        1\n",
              "..               ...      ...\n",
              "199        끝나니까 허무하다        1\n",
              "200          꿈이 이뤄질까        1\n",
              "201       내가 너무 소심한가        1\n",
              "202        말실수 한거 같아        1\n",
              "203      난 머리가 너무 나빠        1\n",
              "\n",
              "[90 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi8h2QvruMxM"
      },
      "source": [
        "okt = Okt()\n",
        "stopwords = ['백주부','ㅋ','ㅎ','ㅠㅠ','ㅜㅜ','^^','의','을','(','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', 'ㄴ','ㅠ',',','0',';','ㅜ','/','~','!','?','♥♥','♡♡','♡','♥']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8CFGGo9uRMV"
      },
      "source": [
        "  def tokenize(data):\n",
        "\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    han = re.compile(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\")\n",
        "\n",
        "    arr  =[]\n",
        "    for sen in data:\n",
        "      sen = re.sub(emoji_pattern, \"\", sen)\n",
        "      sen = re.sub(han, \"\", sen)\n",
        "      temp = okt.morphs(sen, stem = True)#True\n",
        "      temp = [word for word in temp if not word in stopwords]\n",
        "      arr.append(' '.join(temp))\n",
        "      #arr.append(temp)\n",
        "    return arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwuAmy0wmrZ"
      },
      "source": [
        "tokenized_data = tokenize(data_ver1['Sentence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjKEu3BGSFz8"
      },
      "source": [
        "#tokenized_data1 = tokenize(data_ver1['Sentence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTXGwJeF60_5"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo5Z-sNk_cJz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tuj4OOrD7oAN"
      },
      "source": [
        "#print(len(data_ver1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14u_yHMV64Am"
      },
      "source": [
        "# vectorize = TfidfVectorizer(max_features = 5000)\n",
        "# vectorized_data = vectorize.fit_transform(tokenized_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoIkJBF6WVyW"
      },
      "source": [
        "train_D = (tokenized_data)\n",
        "train_L = data_ver1['Emotion']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnMa8mYR6-oL"
      },
      "source": [
        "train_D, test_D,train_L, test_L = train_test_split(tokenized_data, data_ver1['Emotion'].values , random_state =42, train_size= 0.8, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klOZVvUNSIp8"
      },
      "source": [
        "#train_D2, test_D2,train_L2, test_L2 = train_test_split(tokenized_data1, data_ver1['Emotion'].values , random_state =42, train_size= 0.8, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP_1uI2cDHqE"
      },
      "source": [
        "# lgbm = lightgbm.LGBMClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aatr7MADSog"
      },
      "source": [
        "# lgbm.fit(train_D, train_L)\n",
        "# pred = lgbm.predict(test_D)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vVGZwZYDXGQ"
      },
      "source": [
        "# accuracy_score(pred, test_L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWAsArVpF9bI"
      },
      "source": [
        "# def featurize_rnn(corpus,wdim,maxlen):\n",
        "#     rnn_total = np.zeros((len(corpus),maxlen,wdim))\n",
        "#     for i in range(len(corpus)):\n",
        "#         if i%1000 ==0:\n",
        "#             print(i)\n",
        "#         s = corpus[i]\n",
        "#         for j in range(len(s)):\n",
        "#             if s[-j-1] in model_ft and j < maxlen:\n",
        "#                 rnn_total[i][-j-1,:] = model_ft[s[-j-1]]\n",
        "#     return rnn_total\n",
        "\n",
        "# #fci_rec = featurize_rnn(train_D + test_D,100,7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqgEag-i-hCI"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one = OneHotEncoder()\n",
        "train_L = one.fit_transform(np.array(train_L).reshape(-1,1)).toarray()\n",
        "test_L = one.transform(np.array(test_L).reshape(-1,1)).toarray()\n",
        "#train_L2 = one.transform(np.array(train_L2).reshape(-1,1)).toarray()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdDFf-oXAChM"
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(Embedding(5000, 100))#, trainable = True))\n",
        "# model.add(Bidirectional(LSTM(128, activation = 'tanh')))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(128))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(train_L.shape[1], activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znr1Swe8F2BK"
      },
      "source": [
        "import tensorflow_hub as hub \n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import urllib.request\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRUDoJdSGNqq"
      },
      "source": [
        "# ! pip uninstall tensorflow tensorflow_hub tensorflowjs\n",
        "# ! pip install tensorflow==1.15 tensorflow_hub==0.5.0 tensorflowjs==1.2.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsnJ3-kGGCtA"
      },
      "source": [
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=True)\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z61cYVloAjge"
      },
      "source": [
        "def ELMoEmbedding(x):\n",
        "  return elmo(tf.squeeze(tf.cast(x, tf.string)), as_dict = True, signature = 'default')['default']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNX6jXUfJ5kq"
      },
      "source": [
        "from keras.callbacks import TensorBoard#ModelCheckpoint\n",
        "##es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=4)\n",
        "#mc = ModelCheckpoint('best_t_elmo_model_onlytrain.h5', monitor='val_acc', mode='max', verbose=1, save_weights_only=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgAEQan4sRWX"
      },
      "source": [
        "# class ElmoEmbeddingLayer(tf.keras.layers.Layer):\n",
        "#     \"\"\"Taken from: \n",
        "#     https://github.com/strongio/keras-elmo/blob/master/Elmo%20Keras.ipynb\"\"\"\n",
        "#     def __init__(self, **kwargs):\n",
        "#         self.dimensions = 1024\n",
        "#         self.trainable=False\n",
        "#         super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
        "#     def build(self, input_shape):\n",
        "#         self.elmo = hub.Module(\n",
        "#             'https://tfhub.dev/google/elmo/1', \n",
        "#             trainable=self.trainable,\n",
        "#             name=\"{}_module\".format(self.name)\n",
        "#         )\n",
        "#         # Changed assuming trainable weights might be set using \n",
        "#         super(ElmoEmbeddingLayer, self).build(input_shape)\n",
        "#     def call(self, x, mask=None):\n",
        "#         result = self.elmo(\n",
        "#             K.squeeze(K.cast(x, tf.string), axis=1),\n",
        "#             as_dict=True,\n",
        "#             signature='default',\n",
        "#         )['default']\n",
        "#         return result\n",
        "#     def compute_mask(self, inputs, mask=None):\n",
        "#         return K.not_equal(inputs, '--PAD--')\n",
        "#     def compute_output_shape(self, input_shape):\n",
        "#         return (input_shape[0], self.dimensions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnbX9VvwIrRi",
        "outputId": "3810dd6b-a900-4072-d595-3e352b9da2bd"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Lambda, Input, Dropout\n",
        "from keras import optimizers\n",
        "# model = Sequential()\n",
        "# model.add(tf.keras.layers.InputLayer(dtype=  'string', input_shape = (1,)))\n",
        "# model.add(ElmoEmbeddingLayer())\n",
        "# model.add(tf.keras.layers.Dense(256, activation = 'relu'))\n",
        "# model.add(tf.keras.layers.Dropout(0.5))\n",
        "# model.add(tf.keras.layers.Dense(4, activation=  'softmax'))\n",
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding_layer = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
        "hidden_layer = Dense(256, activation='relu')(embedding_layer)\n",
        "dropout = Dropout(0.5)(hidden_layer)\n",
        "output_layer = Dense(4, activation='softmax')(dropout)\n",
        "model = Model(inputs=[input_text], outputs=output_layer)\n",
        "# sess = tf.Session()\n",
        "# K.set_session(sess)\n",
        "# sess.run(tf.global_variables_initializer())\n",
        "# sess.run(tf.tables_initializer())\n",
        "adam = optimizers.Adam(clipvalue = 0.6,  learning_rate = 1e-3)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc'])#'categorical_crossentropy'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWH1YLwGUBQO"
      },
      "source": [
        "import datetime\r\n",
        "log_dir= 'logs/fit/' + datetime.datetime.now().strftime(\"%Y%m%d - %H%M%S\")\r\n",
        "tensorboard_callback = TensorBoard(log_dir= log_dir, histogram_freq = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9QjOiwXLx3j",
        "outputId": "dc106b09-ffa7-43a1-c4e5-47e8d3c57c8d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_5 (Lambda)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 263,428\n",
            "Trainable params: 263,428\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "dt2oHaS-I_k6",
        "outputId": "8579e963-c9b3-4c11-c2c9-25ff10862789"
      },
      "source": [
        "history = model.fit(np.asarray(train_D), np.asarray(train_L),epochs = 20,batch_size=  30,validation_split=  0.2)#, validation_data = (np.array(test_D), np.array(test_L)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13951 samples, validate on 3488 samples\n",
            "Epoch 1/20\n",
            "13950/13951 [============================>.] - ETA: 0s - loss: 1.3786 - acc: 0.3035"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-64ac26e12631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, validation_data = (np.array(test_D), np.array(test_L)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: input must be a vector, got shape: []\n\t [[{{node lambda_5/module_2_apply_default/StringSplit}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-ptoRfnVxHu"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "with open('elmo_data.json', 'w') as f:\r\n",
        "    json.dump(str(history.history), f)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWVaNJaaYG17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4833e4-b602-45d8-b573-c5cfbd82bcc1"
      },
      "source": [
        "with open('elmo_data.json', 'r') as f:\r\n",
        "  d = json.load(f)\r\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': [1.2872377336025238, 1.2467638552188873, 1.1991693675518036, 1.2291805446147919, 1.2139660716056824, 1.2411887645721436, 1.2541942596435547, 1.3014951646327972, 1.2422834634780884, 1.3597261905670166, 1.2623080909252167, 1.2978671789169312, 1.288278877735138, 1.2837488949298859, 1.3434213995933533, 1.338758796453476, 1.371456891298294, 1.4080892503261566, 1.383622407913208, 1.4326256811618805], 'val_acc': [0.30000001192092896, 0.375, 0.44999998807907104, 0.375, 0.44999998807907104, 0.42500001192092896, 0.42500001192092896, 0.44999998807907104, 0.42500001192092896, 0.4000000059604645, 0.4749999940395355, 0.4749999940395355, 0.4749999940395355, 0.4749999940395355, 0.4749999940395355, 0.4749999940395355, 0.5, 0.44999998807907104, 0.4749999940395355, 0.4749999940395355], 'loss': [1.5479077845811844, 1.2239396125078201, 1.1383262798190117, 0.9752128422260284, 0.8443870432674885, 0.7926311455667019, 0.6706805564463139, 0.6317084934562445, 0.575370866805315, 0.5424670688807964, 0.5259842593222857, 0.47978923469781876, 0.4219367541372776, 0.3640218507498503, 0.3073748229071498, 0.29658156260848045, 0.27829851768910885, 0.2724774079397321, 0.19950731191784143, 0.19184225890785456], 'acc': [0.29375, 0.41875, 0.4375, 0.63125, 0.66875, 0.71875, 0.74375, 0.80625, 0.79375, 0.825, 0.81875, 0.83125, 0.86875, 0.9375, 0.94375, 0.94375, 0.95, 0.95, 0.9875, 0.98125]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr1LhlGLUIpw"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0-ex8T-UJR2"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KffNUGUjoMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5585253-4527-41e6-aabf-a61b90bcc781"
      },
      "source": [
        "import time\n",
        "s = time.time()\n",
        "model.evaluate(np.asarray(test_D), np.array(test_L))\n",
        "#print(time.time() - s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58/58 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5901973288634728, 0.36206895112991333]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s55eXRbDnShj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0ca3d3-adb6-49ba-b9f7-e3ec4d6cbc36"
      },
      "source": [
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding_layer = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
        "hidden_layer = Dense(256, activation='relu')(embedding_layer)\n",
        "dropout = Dropout(0.5)(hidden_layer)\n",
        "output_layer = Dense(4, activation='softmax')(dropout)\n",
        "loaded_model = Model(inputs=[input_text], outputs=output_layer)\n",
        "adam = optimizers.Adam(clipvalue = 0.6,  learning_rate = 1e-3)\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTqCAWhBkJXL"
      },
      "source": [
        "from keras.models import load_model\n",
        "model.save_weights('elmo_weight.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCNoBgxWuQWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1291a2-e491-41b3-b789-e663015a7a59"
      },
      "source": [
        "import time\n",
        "s = time.time()\n",
        "loaded_model.load_weights('elmo_weight.h5')\n",
        "loaded_model.evaluate(np.asarray(test_D), np.array(test_L))\n",
        "#print(time.time() - s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58/58 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5901973288634728, 0.36206895112991333]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3wI50fJnesB"
      },
      "source": [
        "#loaded_model.evaluate(np.asarray(test_D), np.array(test_L))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKttA75JZqNu"
      },
      "source": [
        "# ! pip uninstall tensorflow\n",
        "# ! pip install tensorflow== 2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTEOaq7-aDxk"
      },
      "source": [
        "model.save('elmo.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJIpHrqrZD4B"
      },
      "source": [
        "import json\n",
        "model_json = model.to_json()\n",
        "with open(\"elmo_model.json\", \"w\") as json_file : \n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKERXlIyYDxA"
      },
      "source": [
        "load_model('elmo_weight.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Mmq9AoJRKR"
      },
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  # new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
        "  # new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
        "  new_sentence = tokenize(new_sentence)\n",
        "  #new_sentence = ' '.join(new_sentence)\n",
        "  #new_sentence = [word for word in ' '.join(new_sentence)]\n",
        "  print(new_sentence)\n",
        "\n",
        "  pred= model.predict(np.asarray(new_sentence)) # 예측\n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPOTg33AU8bM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b305917-d16a-4fc0-c2b2-4bfab0157f04"
      },
      "source": [
        "sentiment_predict(['dP', ''])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['개 빡치다 시발 진짜', '']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7442806 , 0.16920544, 0.02762927, 0.05888473],\n",
              "       [0.2507515 , 0.2503804 , 0.24899194, 0.24987617]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "853FMI9jWFrb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}