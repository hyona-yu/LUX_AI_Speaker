# -*- coding: utf-8 -*-
"""capstone_emotion_check.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nrzkPBHmnPWVpG337eXIcDtZanH2HIOU

아직 tts 안너헝다. 감정분석하는 함수. wordindex.json이랑 h5파일 있어야해
"""

! pip install konlpy

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt
import re
import urllib.request
from konlpy.tag import Okt
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import re

from tensorflow.keras.models import load_model
import json

okt = Okt()
stopwords = ['백주부','ㅋ','ㅎ','ㅠ','ㅜㅜ','^^','의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', 'ㄴ','ㅠ',',','0',';','ㅜ','/','~','!','?','♥♥','♡♡','♡','♥']
tokenizer = Tokenizer(num_words= 4771)

max_len = 7
num_words = 4770

with open('wordIndex.json') as json_file:
  word_index = json.load(json_file)
  tokenizer.word_index = word_index

def tokenize(data):
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           "]+", flags=re.UNICODE)
    han = re.compile(r'[ㄱ-ㅎㅏ-ㅣ!?~,".\n\r#\ufeff\u200d]')

    arr  =[]

    for sen in data:
      sen = re.sub(emoji_pattern, "", sen)
      sen = re.sub(han, "", sen)
      temp = okt.morphs(sen, stem = True)#True
      temp = [word for word in temp if not word in stopwords]
      arr.append(temp)
    return arr

loaded_model = load_model('emotion_text_detection.h5')

def sentiment_predict(new_sentence):
  new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화
  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거
  #print(new_sentence)
  encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩
  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩
  #print(pad_new)

  pred= loaded_model.predict(pad_new) # 예측
  return pred

pred = (sentiment_predict('와 이제부터 휴가다')[0])

print(pred)
print(np.argmax(pred))

#화남 슬픔 중립  행복 // 8가지

import random
import numpy as np 
def emotion_to_ans(emotion):
  #methods = {'mp3':0, 'sentence':1, 'words':2 }# 감성노래, 감성글, 힘내요 대답!
  sentence_path = ''
  get_method = random.randrange(0,3) # mp3 불러올건지 sentence 불러올건지 감성글 불러올건지 
  words = ['괜찮아요', '힘내요','내일은 다시 웃어봐요']
  if get_method =='0':
    method_mp3(emotion)

  else if get_method =='1':
    method_sen(emotion)

  else if get_method =='2':
    method_words(emotion)

!pip install pygame

import pygame

def method_mp3(emotion):
  mp3_path = '/content/'
  mp3s = ['0_Winner_Winner_Funky_Chicken_Dinner.mp3']
  emotion_mp3 = []
  for p in mp3s:
    if p.split('_')[0] == str(emotion):
      emotion_mp3.append(p)
  idx = random.randrange(0, len(emotion_mp3))
  freq = 44100    # sampling rate, 44100(CD), 16000(Naver TTS), 24000(google TTS)
  bitsize = -16   # signed 16 bit. support 8,-8,16,-16
  channels = 2    # 1 is mono, 2 is stereo
  buffer = 4096   # number of samples (experiment to get right sound)
  print(mp3_path + emotion_mp3[idx])
  # default : pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=4096)
  pygame.mixer.init(freq, size=-16, channels=1, buffer=320)
  pygame.mixer.music.load(mp3_path + emotion_mp3[idx])
  pygame.mixer.music.play()

  clock = pygame.time.Clock()
  while pygame.mixer.music.get_busy():
      clock.tick(30)
  pygame.mixer.quit()

import os
os.getcwd()

method_mp3(0)

random.randrange(0,3)

