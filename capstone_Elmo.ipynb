{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "capstone_Elmo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyODnydAfdMAIkrjZsJk1t6T",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyona-yu/LUX_AI_Speaker/blob/main/capstone_Elmo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLUMNjrWHVRi"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2HqB11UuEAa",
        "outputId": "c1b7706c-0ff5-41cc-f119-517fb708f8da"
      },
      "source": [
        "! pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.1.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve78bK4-zBqK"
      },
      "source": [
        "# !pip install gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEPwd9cy-8Sa"
      },
      "source": [
        "# !pip install fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04l9HIQup3fu"
      },
      "source": [
        "# ! pip install senticnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PmvpUbIp7Vr"
      },
      "source": [
        "# from senticnet.babelsenticnet import BabelSenticNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rcenv-NYp_cd"
      },
      "source": [
        "# sn = BabelSenticNet('kr')\n",
        "# sn.concept('사랑')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKMJEPl-uCYp"
      },
      "source": [
        "# from sklearn.utils import class_weight\n",
        "# class_weights_fci = class_weight.compute_class_weight('balanced', np.unique(data_ver2['Emotion']), data_ver2['Emotion'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psKISsXWuxYt"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout, GRU, Conv1D,Flatten,GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1L_SgkHti3r"
      },
      "source": [
        "# def featurize_rnn(corpus,wdim,maxlen):\n",
        "#     rnn_total = np.zeros((len(corpus),maxlen,wdim))\n",
        "#     for i in range(len(corpus)):\n",
        "#         if i%1000 ==0:\n",
        "#             print(i)\n",
        "#         s = corpus[i]\n",
        "#         for j in range(len(s)):\n",
        "#             if s[-j-1] in data_ver2['Sentence'] and j < maxlen:\n",
        "#                 rnn_total[i][-j-1,:] = model_ft[s[-j-1]]\n",
        "#     return rnn_total\n",
        "\n",
        "# data = featurize_rnn(tokenized_data,100,30)\n",
        "\n",
        "# from keras.layers import LSTM\n",
        "# from keras.layers import Bidirectional\n",
        "\n",
        "# def validate_bilstm(result,y,hidden_lstm,hidden_dim,cw,filename):\n",
        "#     model = Sequential()\n",
        "#     model.add(Bidirectional(LSTM(hidden_lstm), input_shape=(len(result[0]), len(result[0][0]))))\n",
        "#     model.add(layers.Dense(hidden_dim, activation='relu'))\n",
        "#     model.add(layers.Dense(int(max(y)+1), activation='softmax'))\n",
        "#     model.summary()\n",
        "#     model.compile(optimizer='Adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "#     filepath=filename+\"-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "#     checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, mode='max')\n",
        "#     callbacks_list = [metricsf1macro,checkpoint]\n",
        "#     model.fit(result,y,validation_split=0.1,epochs=30,batch_size=16,callbacks=callbacks_list,class_weight=cw)\n",
        "\n",
        "# validate_bilstm(data,data_ver2['Emotion'],32,128,class_weights_fci,'model/tutorial/rec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9uDwINArYU1"
      },
      "source": [
        "# for t in tokenized_data[0]:\n",
        "#   print(t)\n",
        "#   try:\n",
        "#     print(sn.concept(t))\n",
        "#   except:\n",
        "#     continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qnO5hjX_e0z"
      },
      "source": [
        "#! git clone https://github.com/facebookresearch/fastText.git\n",
        "# ! cd fastText\n",
        "# ! sudo python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO1yUs52tqOg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRsWEM2UuCA5"
      },
      "source": [
        "#data_ver1 = pd.read_csv('train.csv')\n",
        "data_ver2= pd.read_csv('train2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi8h2QvruMxM"
      },
      "source": [
        "okt = Okt()\n",
        "stopwords = ['백주부','ㅋ','ㅎ','ㅠㅠ','ㅜㅜ','^^','의','을','(','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', 'ㄴ','ㅠ',',','0',';','ㅜ','/','~','!','?','♥♥','♡♡','♡','♥']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8CFGGo9uRMV"
      },
      "source": [
        "  def tokenize(data):\n",
        "\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    han = re.compile(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\")\n",
        "\n",
        "    arr  =[]\n",
        "    for sen in data:\n",
        "      sen = re.sub(emoji_pattern, \"\", sen)\n",
        "      sen = re.sub(han, \"\", sen)\n",
        "      temp = okt.morphs(sen, stem = True)#True\n",
        "      temp = [word for word in temp if not word in stopwords]\n",
        "      arr.append(' '.join(temp))\n",
        "      #arr.append(temp)\n",
        "    return arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqwuAmy0wmrZ"
      },
      "source": [
        "tokenized_data = tokenize(data_ver2['Sentence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjKEu3BGSFz8"
      },
      "source": [
        "#tokenized_data1 = tokenize(data_ver1['Sentence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTXGwJeF60_5"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo5Z-sNk_cJz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tuj4OOrD7oAN"
      },
      "source": [
        "#print(len(data_ver1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14u_yHMV64Am"
      },
      "source": [
        "# vectorize = TfidfVectorizer(max_features = 5000)\n",
        "# vectorized_data = vectorize.fit_transform(tokenized_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoIkJBF6WVyW"
      },
      "source": [
        "train_D = (tokenized_data)\n",
        "train_L = data_ver2['Emotion']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnMa8mYR6-oL"
      },
      "source": [
        "train_D, test_D,train_L, test_L = train_test_split(tokenized_data, data_ver2['Emotion'].values , random_state =42, train_size= 0.8, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klOZVvUNSIp8"
      },
      "source": [
        "#train_D2, test_D2,train_L2, test_L2 = train_test_split(tokenized_data1, data_ver1['Emotion'].values , random_state =42, train_size= 0.8, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP_1uI2cDHqE"
      },
      "source": [
        "# lgbm = lightgbm.LGBMClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aatr7MADSog"
      },
      "source": [
        "# lgbm.fit(train_D, train_L)\n",
        "# pred = lgbm.predict(test_D)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vVGZwZYDXGQ"
      },
      "source": [
        "# accuracy_score(pred, test_L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWAsArVpF9bI"
      },
      "source": [
        "# def featurize_rnn(corpus,wdim,maxlen):\n",
        "#     rnn_total = np.zeros((len(corpus),maxlen,wdim))\n",
        "#     for i in range(len(corpus)):\n",
        "#         if i%1000 ==0:\n",
        "#             print(i)\n",
        "#         s = corpus[i]\n",
        "#         for j in range(len(s)):\n",
        "#             if s[-j-1] in model_ft and j < maxlen:\n",
        "#                 rnn_total[i][-j-1,:] = model_ft[s[-j-1]]\n",
        "#     return rnn_total\n",
        "\n",
        "# #fci_rec = featurize_rnn(train_D + test_D,100,7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqgEag-i-hCI"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one = OneHotEncoder()\n",
        "train_L = one.fit_transform(np.array(train_L).reshape(-1,1)).toarray()\n",
        "test_L = one.transform(np.array(test_L).reshape(-1,1)).toarray()\n",
        "#train_L2 = one.transform(np.array(train_L2).reshape(-1,1)).toarray()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdDFf-oXAChM"
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(Embedding(5000, 100))#, trainable = True))\n",
        "# model.add(Bidirectional(LSTM(128, activation = 'tanh')))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(128))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(train_L.shape[1], activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znr1Swe8F2BK"
      },
      "source": [
        "import tensorflow_hub as hub \n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import urllib.request\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRUDoJdSGNqq"
      },
      "source": [
        "# ! pip uninstall tensorflow tensorflow_hub tensorflowjs\n",
        "# ! pip install tensorflow==1.15 tensorflow_hub==0.5.0 tensorflowjs==1.2.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsnJ3-kGGCtA"
      },
      "source": [
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z61cYVloAjge"
      },
      "source": [
        "def ELMoEmbedding(x):\n",
        "  return elmo(tf.squeeze(tf.cast(x, tf.string)), as_dict = True, signature = 'default')['default']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNX6jXUfJ5kq"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_t_elmo_model_onlytrain.h5', monitor='val_acc', mode='max', verbose=1, save_weights_only=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgAEQan4sRWX"
      },
      "source": [
        "# class ElmoEmbeddingLayer(tf.keras.layers.Layer):\n",
        "#     \"\"\"Taken from: \n",
        "#     https://github.com/strongio/keras-elmo/blob/master/Elmo%20Keras.ipynb\"\"\"\n",
        "#     def __init__(self, **kwargs):\n",
        "#         self.dimensions = 1024\n",
        "#         self.trainable=False\n",
        "#         super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
        "#     def build(self, input_shape):\n",
        "#         self.elmo = hub.Module(\n",
        "#             'https://tfhub.dev/google/elmo/1', \n",
        "#             trainable=self.trainable,\n",
        "#             name=\"{}_module\".format(self.name)\n",
        "#         )\n",
        "#         # Changed assuming trainable weights might be set using \n",
        "#         super(ElmoEmbeddingLayer, self).build(input_shape)\n",
        "#     def call(self, x, mask=None):\n",
        "#         result = self.elmo(\n",
        "#             K.squeeze(K.cast(x, tf.string), axis=1),\n",
        "#             as_dict=True,\n",
        "#             signature='default',\n",
        "#         )['default']\n",
        "#         return result\n",
        "#     def compute_mask(self, inputs, mask=None):\n",
        "#         return K.not_equal(inputs, '--PAD--')\n",
        "#     def compute_output_shape(self, input_shape):\n",
        "#         return (input_shape[0], self.dimensions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnbX9VvwIrRi",
        "outputId": "c78c5347-f011-4e9c-d4a2-eceb86a50e52"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Lambda, Input, Dropout\n",
        "from keras import optimizers\n",
        "# model = Sequential()\n",
        "# model.add(tf.keras.layers.InputLayer(dtype=  'string', input_shape = (1,)))\n",
        "# model.add(ElmoEmbeddingLayer())\n",
        "# model.add(tf.keras.layers.Dense(256, activation = 'relu'))\n",
        "# model.add(tf.keras.layers.Dropout(0.5))\n",
        "# model.add(tf.keras.layers.Dense(4, activation=  'softmax'))\n",
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding_layer = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
        "hidden_layer = Dense(256, activation='relu')(embedding_layer)\n",
        "dropout = Dropout(0.5)(hidden_layer)\n",
        "output_layer = Dense(4, activation='softmax')(dropout)\n",
        "model = Model(inputs=[input_text], outputs=output_layer)\n",
        "# sess = tf.Session()\n",
        "# K.set_session(sess)\n",
        "# sess.run(tf.global_variables_initializer())\n",
        "# sess.run(tf.tables_initializer())\n",
        "adam = optimizers.Adam(clipvalue = 0.6,  learning_rate = 1e-3)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9QjOiwXLx3j",
        "outputId": "7db89478-590f-48cd-c7f6-11fa9d37bb54"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_2 (Lambda)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 263,428\n",
            "Trainable params: 263,428\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt2oHaS-I_k6",
        "outputId": "0fb8325d-280b-4594-e63a-0f818922b9e9"
      },
      "source": [
        "history = model.fit(np.asarray(train_D), np.asarray(train_L),epochs = 20,batch_size=  30)#,validation_split=  0.1)#, validation_data = (np.array(test_D), np.array(test_L)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.1226 - accuracy: 0.6226\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.9401 - accuracy: 0.6631\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.7868 - accuracy: 0.7271\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.7848 - accuracy: 0.7036\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.7154 - accuracy: 0.7377\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.6350 - accuracy: 0.7783\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.6098 - accuracy: 0.7377\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.8017\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5568 - accuracy: 0.7868\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4773 - accuracy: 0.8230\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4268 - accuracy: 0.8550\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4093 - accuracy: 0.8550\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3636 - accuracy: 0.8614\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3457 - accuracy: 0.8827\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3211 - accuracy: 0.8998\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2768 - accuracy: 0.9147\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2519 - accuracy: 0.9126\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2551 - accuracy: 0.9382\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.2094 - accuracy: 0.9403\n",
            "Epoch 20/20\n",
            "390/469 [=======================>......] - ETA: 0s - loss: 0.1923 - accuracy: 0.9462"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KffNUGUjoMF"
      },
      "source": [
        "import time\n",
        "s = time.time()\n",
        "model.evaluate(np.asarray(train_D), np.array(train_L))\n",
        "#print(time.time() - s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s55eXRbDnShj"
      },
      "source": [
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding_layer = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
        "hidden_layer = Dense(256, activation='relu')(embedding_layer)\n",
        "dropout = Dropout(0.5)(hidden_layer)\n",
        "output_layer = Dense(4, activation='softmax')(dropout)\n",
        "loaded_model = Model(inputs=[input_text], outputs=output_layer)\n",
        "adam = optimizers.Adam(clipvalue = 0.6,  learning_rate = 1e-3)\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCNoBgxWuQWL"
      },
      "source": [
        "import time\n",
        "s = time.time()\n",
        "loaded_model.load_weights('elmo_weight.h5')\n",
        "loaded_model.evaluate(np.asarray(test_D), np.array(test_L))\n",
        "print(time.time() - s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3wI50fJnesB"
      },
      "source": [
        "#loaded_model.evaluate(np.asarray(test_D), np.array(test_L))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WTqCAWhBkJXL"
      },
      "source": [
        "from keras.models import load_model\n",
        "model.save_weights('best_t_elmo_model_onlytrain_weight.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKttA75JZqNu"
      },
      "source": [
        "# ! pip uninstall tensorflow\n",
        "# ! pip install tensorflow== 2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTEOaq7-aDxk"
      },
      "source": [
        "model.save('elmo.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJIpHrqrZD4B"
      },
      "source": [
        "import json\n",
        "model_json = model.to_json()\n",
        "with open(\"elmo_model.json\", \"w\") as json_file : \n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKERXlIyYDxA"
      },
      "source": [
        "load_model('elmo_weight.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Mmq9AoJRKR"
      },
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  # new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
        "  # new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
        "  new_sentence = tokenize(new_sentence)\n",
        "  #new_sentence = ' '.join(new_sentence)\n",
        "  #new_sentence = [word for word in ' '.join(new_sentence)]\n",
        "  print(new_sentence)\n",
        "\n",
        "  pred= model.predict(np.asarray(new_sentence)) # 예측\n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPOTg33AU8bM"
      },
      "source": [
        "sentiment_predict(['아오 진짜',''])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "853FMI9jWFrb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}